{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Python SDK\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "This is a simple inference example using MNIST model. To run the following examples, you must install NPU driver, firmware, and runtime by following [FuriosaAI Driver, Firmware, Runtime Installation Guide](https://furiosa-ai.github.io/docs/latest/ko/software/installation.html).\n",
    "\n",
    "After then, you need to install the following python packages:\n",
    "```sh\n",
    "pip install furiosa-sdk matplotlib mnist\n",
    "```\n",
    "Or, you can run the following command to install all dependent packages for all notebook examples at once:\n",
    "```sh\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Then, you are now ready to run the following examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking environment\n",
    "First, let's check if your NPU device is ready as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[0m+\u001b[0m\u001b[0m------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m------------------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m-------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m--------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m--------------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m---------\u001b[0m\u001b[0m+\n",
      "\u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m\u001b[1mNPU \u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m\u001b[1mName            \u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m\u001b[1mTemp.\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m\u001b[1mPower \u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m\u001b[1mPCI-BDF     \u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m\u001b[1mPCI-DEV\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m+\u001b[0m\u001b[0m------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m------------------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m-------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m--------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m--------------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m---------\u001b[0m\u001b[0m+\n",
      "\u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0mnpu4\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0mFuriosaAI Warboy\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m 38¬∞C\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m0.00 W\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m0000:a1:00.0\u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m \u001b[0m503:0  \u001b[0m\u001b[0m \u001b[0m\u001b[0m|\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m+\u001b[0m\u001b[0m------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m------------------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m-------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m--------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m--------------\u001b[0m\u001b[0m+\u001b[0m\u001b[0m---------\u001b[0m\u001b[0m+\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!furiosactl info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your device and environment, some information can be different from the output shown above. `furiosactl` prints out the summary of your NPU device.\n",
    "\n",
    "Then, let's make sure that your SDK is ready to run immediately by running the following command. If you see any error here, please follow the instructions at\n",
    "* [FuriosaAI Driver, Firmware, Runtime Installation Guide](https://furiosa-ai.github.io/docs/latest/ko/software/installation.html)\n",
    "* [Setting up a Python Environment](https://furiosa-ai.github.io/docs/latest/ko/software/python-sdk.html#python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libnpu.so --- v2.0, built @ fe1fca3\n",
      "Furiosa SDK Runtime .release:0.5.0.dev0+94f7e99a653d50d1fdf8daca2495e32a95b364d0 (libnux 0.5.0 407c0c51f-modified 2021-11-22 20:18:37)\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from furiosa import runtime;print(runtime.__full_version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are going to show how you can do inferences through `furiosa-sdk` with NPU. For that, we need a model and sample dataset. Here, we will use MNIST model and its dataset. This example already includes the MNIST model at `./models` directory, and its dataset can be quickly available by importing `mnist` python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import MNIST dataset package\n",
    "import mnist\n",
    "\n",
    "# The following line will download the MNIST dataset through the network.\n",
    "train_images = mnist.train_images()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you already have the sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running furiosa-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable `furiosa-sdk` in your Python script, you need to import `furiosa.runtime` simply as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libnpu.so --- v2.0, built @ fe1fca3\n"
     ]
    }
   ],
   "source": [
    "from furiosa.runtime import session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's import other python packages for numpy array and images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling Tflite or Onnx model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the first step to run inferences on NPU, you have to create a `Session` object by calling `session.create()`. This step involves a model compilation and NPU initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the compilation log into /home/jovyan/.local/state/furiosa/logs/compile-20211211182856-z8ivnr.log\n",
      "Using furiosa-compiler 0.5.0 (rev: 407c0c51f-modified built at 2021-11-22 20:18:37)\n",
      "\u001b[2m2021-12-11T18:28:56.341706Z\u001b[0m \u001b[32m INFO\u001b[0m Npu (npu4pe0-1) is being initialized\n",
      "\u001b[2m2021-12-11T18:28:56.341973Z\u001b[0m \u001b[32m INFO\u001b[0m NuxInner create with pes: [PeId(0)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/6] üîç   Compiling from tflite to dfg\n",
      "Done in 0.011897176s\n",
      "[2/6] üîç   Compiling from dfg to ldfg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2021-12-11T18:29:02.958903Z\u001b[0m \u001b[32m INFO\u001b[0m [Profiler] Program binary notification has been arrived. Cleanup current profile queue data\n",
      "CPU times: user 6.62 s, sys: 32.5 ms, total: 6.65 s\n",
      "Wall time: 6.64 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done in 6.589308s\n",
      "[3/6] üîç   Compiling from ldfg to cdfg\n",
      "Done in 0.000348525s\n",
      "[4/6] üîç   Compiling from cdfg to gir\n",
      "Done in 0.003241408s\n",
      "[5/6] üîç   Compiling from gir to lir\n",
      "Done in 0.000921878s\n",
      "[6/6] üîç   Compiling from lir to enf\n",
      "Done in 0.005478269s\n",
      "‚ú®  Finished in 6.6115346s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sess = session.create('models/MNIST_MobileNet_v2_uint8_quant_without_avgpool_softmax.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`session.create()` can take more options. As an example, `device` allows to specify a certain NPU device. For example, you can set `device=\"npu0pe0-1\"` to use a 2PE-fusioned NPU. You can also use 2 PEs individually if you set `device=\"npu0pe0\"` or `device=\"npu0pe1\"`. You can find more options in Python API Reference.\n",
    "\n",
    "Once `session` object is created, you are able get model information, such as input and output tensors shapes and their data type as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "{0: TensorDesc(shape=(1, 28, 28, 1), dtype=UINT8, format=NHWC, size=784, len=784)}\n",
      "Outputs:\n",
      "{0: TensorDesc(shape=(1, 10), dtype=UINT8, format=??, size=10, len=10)}\n"
     ]
    }
   ],
   "source": [
    "sess.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorDesc(shape=(1, 28, 28, 1), dtype=UINT8, format=NHWC, size=784, len=784)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.inputs() # returns List[TensorDesc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TensorDesc(shape=(1, 10), dtype=UINT8, format=??, size=10, len=10)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.outputs() # returns List[TensorDesc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try to run an inference from the `Session` object. For that, we need to prepare an sample image for MNIST model. `Session.run()` is the function to run an inference. It takes one or more *numpy* arrays as input tensors and returns `TensorArray` which can be also converted to *numpy* array. \n",
    "\n",
    "The followings transform one of MNIST training images to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1, 28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb9c460a7c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Converts a single image to a numpy array `input`\n",
    "input = np.array(train_images[2:3].reshape(1, 28, 28, 1), np.uint8)\n",
    "print(sess.input(0).shape)\n",
    "print(input.shape)\n",
    "\n",
    "# Show the input image\n",
    "test_image = input.reshape(28, 28)\n",
    "plt.figure()\n",
    "plt.imshow(test_image, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following runs 100 inferences and measure their walltimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234 ¬µs ¬± 37.4 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n100\n",
    "\n",
    "idx = random.randint(0, 59999)\n",
    "input = np.array(train_images[idx:idx+1].reshape(1, 28, 28, 1), np.uint8)\n",
    "outputs = sess.run(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Session.run()` returns a list of tensors, and this model has only one output tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Tensor(shape=(1, 10), dtype=UINT8)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = sess.run(input)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can also handle the output as a list and you can access a specific tensor as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(shape=(1, 10), dtype=UINT8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the output tensor to a numpy array, please run as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[117, 151, 116, 120, 159, 117, 116, 142, 104, 133]], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the output of MNIST model is a tensor shaped `(1, 10)`, each of elements is the probability of the corresponding number. Let's print out what number has the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(outputs[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer will be the same as you saw the above image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Session` will be holding the NPU device until `Session.close()` is called if you keep this notebook session. To run other notebook examples, please free the NPU device as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2021-12-13T00:53:22.317130Z\u001b[0m \u001b[32m INFO\u001b[0m [Profiler] Received a termination signal.\n",
      "\u001b[2m2021-12-13T00:53:22.318872Z\u001b[0m \u001b[32m INFO\u001b[0m session has been destroyed\n"
     ]
    }
   ],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
